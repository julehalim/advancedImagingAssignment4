%%
%% This is file `./samples/longsample.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% apa7.dtx  (with options: `longsample')
%% ----------------------------------------------------------------------
%% 
%% apa7 - A LaTeX class for formatting documents in compliance with the
%% American Psychological Association's Publication Manual, 7th edition
%% 
%% Copyright (C) 2021 by Daniel A. Weiss <daniel.weiss.led at gmail.com>
%% 
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License (LPPL), either
%% version 1.3c of this license or (at your option) any later
%% version.  The latest version of this license is in the file:
%% 
%% http://www.latex-project.org/lppl.txt
%% 
%% Users may freely modify these files without permission, as long as the
%% copyright line and this statement are maintained intact.
%% 
%% This work is not endorsed by, affiliated with, or probably even known
%% by, the American Psychological Association.
%% 
%% ----------------------------------------------------------------------
%% 
\documentclass[man]{apa7}

\usepackage{lipsum}

\usepackage[american]{babel}

\usepackage{caption} % For captioning outside figures
\usepackage{capt-of} % For captioning outside figures

\usepackage{siunitx}

\usepackage{csquotes}
\usepackage[style=apa,backend=biber]{biblatex}
\addbibresource{bibliography.bib}

\title{Parking Occupancy Detection from CCTV Images}
\shorttitle{}
\authorsnames{Jule Valendo Halim -1425567}
\authorsaffiliations{GEOM90038 - Advanced Imaging}

\begin{document}

\maketitle
\tableofcontents
\newpage
\section{Introduction}

Recent developments in data has undergone significant changes from data processing into machine learning due to increased volumes of readily available data (\textcite{KHAN20201444}). The introduction of image-based neural network architecture has allowed the field of computer vision to flourish. Computer vision leverages the power of machine learning to derive meaningful information from visual data, which allows them to take actions and recommendations when they detect issues. Powerful advances in machine learning such as the widely popular transformer model that Chat-GPT is based on has also been adapted to be trained on visual information (\textcite{elnouby2021training}). Figure \ref{fig:representationNeuralNetwork} provides a representation of a neural network, which consists of multiple layers. The input layer is the initial data, and hidden layers calculate the weights of each of these data and propagates them forward to other hidden layers. Finally, the output layer provides probabilities of the desired output (e.g., some classification label).

\begin{minipage}{\linewidth}
  \includegraphics[height=\textheight/4 ,width=\textwidth/1]{figures/sampleNeuralNetwork.png}
  \captionof{figure}{Visual Representation of Layers That Makes Up a Neural Network (\textcite{neuralNetwork})}
  \label{fig:representationNeuralNetwork}
\end{minipage}

Figure \ref{fig:exampleArchitecture} provides a simplified neural network architecture for visual data. The visual data that is placed into the input layer depends on the specific architecture and design. In the case of figure \ref{fig:exampleArchitecture}, a section of the image is placed into the input layer. It is then propagated forward towards additional layers before finally obtaining the results of the output layer, which in this case, attempts to classify the image into four possible species.

\begin{minipage}{\linewidth}
  \includegraphics[height=\textheight/4 ,width=\textwidth/1]{figures/exampleML.jpg}
  \captionof{figure}{Sample Architecture of Machine Learning Being Used in Computer Vision (\textcite{CHAI2021100134})}
  \label{fig:exampleArchitecture}
\end{minipage}

The use of computer vision has been applied to wide range of different fields. For example, \textcite{MEDICAL} discussed the way medical imaging applications in multiple medical areas such as pathology and dermatology has enhanced the level of care provided. Another field in which machine learning has enhanced computer vision is in the automation and digitization of fruit quality measuring and maintainence (\textcite{SUPERMARKET}). Figure \ref{fig:exampleDetection} shows how computer vision can be used to detect cars and humans in images. These detections are generated post-training, where multiple images are provided for training the neural network. The trained neural network can then be given new images or even real time video to detect what they were trained to. However, as seen in figure \ref{fig:exampleDetection}, such neural networks are not perfect, and can misclassify or not detect parts of the image that they are supposed to (e.g., the model did not successfully classify one of the humans walking).

\newpage

\begin{minipage}{\linewidth}
  \includegraphics[height=\textheight/4 ,width=\textwidth/2]{figures/detectionExample.png}
  \captionof{figure}{Sample Image Detection Results of Cars and People Using Deep Learning and RCNN Models(\textcite{KHAN20201444})}
  \label{fig:exampleDetection}
\end{minipage}

In this report, I aim to 


\section{Methods and Results}

\subsection{Visualizing Dataset}

\subsection{Creating Car Detector}

\subsection{Automatic Delineation of Parking Spaces}

\subsection{Evaluation}

\subsection{Improving Accuracy}

\section{Discussion}

\subsection{Accuracy Evaluation}

\subsection{Improvement Based on Assumptions}

\subsection{Challenges and Shortcomings}

\subsection{Scopes of Improvement}

\section{Conclusions and Future Directions}

\section{Appendix}

\printbibliography


\end{document}


















% Theoretical overlap is a parameter that is used in fine registration to indicate how many percent of the points are expected to overlap from one another. Multiple values ranging from 10-100\% were tested. However, 30\% was selected as the final value in order to reduce the final RMS.

% The RMS values show great accuracy, with the coarse registration having an RMS of 1.13cm while the fine registration has 2.27cm of final RMS values.


% \begin{minipage}{\linewidth}
%   \small
%   \captionof{table}{Table Showing Statistical Information About C2C Distances with MLS as the Reference Point Cloud}
%   \setlength{\tabcolsep}{3pt} % reduce column spacing
%   \renewcommand{\arraystretch}{0.8} % reduce row spacing
%   \label{tab:RMStable2}
%   \begin{tabular}{@{}llrr@{}}         \toprule
%   \multicolumn{2}{c}{C2C Distance Statistics }        \\ \toprule{}
%   &  MLS as Reference Point Cloud \\ \midrule
%   Mean (m)      & 0.00091 \\
%   Maximum Value (m)       & 1.55\\
%   Minimum Value (m)       & 0  \\ 
%   Max Error (m) & 0.096 \\\bottomrule
%   \end{tabular}
% \end{minipage}

% \vspace{2em}

%  Meanwhile, figure \ref{fig:c2cMLS} shows the visualization of the C2C distances of only overlapping points in both point clouds.

%  \newpage

%  \begin{minipage}{\linewidth}
%   \includegraphics[height=\textheight/2 ,width=\textwidth/1]{figures/MLSasReference.png}
%   \captionof{figure}{C2C Distance Visualization of MLS as the Reference Point Cloud}
%   \label{fig:c2cMLS}
% \end{minipage}

% As seen in figure \ref{fig:c2cMLS} and table \ref{tab:RMStable2}, the areas in which there is only overlap between the TLS and MLS shows very high quality, where there are no outliers involved. This highlights how the TLS is not prone to many outliers. The distances between both point clouds are also on average, about 0.091cm, compared to the C2C distances when outliers were involved, as seen in table \ref{tab:RMStable}, where the means are about 9cm for the area where all distances were considered. This difference could thus be explained by the outliers inflating the means.

% To further investigate these distances, a histogram of the C2C distance was created from the saved text file of the MLS. Figure \ref{fig:c2chistogram} shows the histogram for C2C distances less than or equal to 1 and distances greater than 1. These distances are based on the initial C2C distance calculations in table \ref{tab:RMStable}.

% \begin{minipage}{\linewidth}
%   \includegraphics[height=\textheight/4 ,width=\textwidth/2]{figures/MLSC2CHistogramWithLine.png}
%   \includegraphics[height=\textheight/4 ,width=\textwidth/2]{figures/MLSC2CHistogramWithLine2.png}
%   \captionof{figure}{Probability distribution of distances less than or equal to 1 (left) and distances higher than 1(right). Note that frequency for the left table is multiplied by \num{1e8}}
%   \label{fig:c2chistogram}
% \end{minipage}



% \begin{minipage}{\linewidth}
%   \includegraphics[height=\textheight/4 ,width=\textwidth/2]{figures/grossError.png}
%   \captionof{figure}{Area With Large C2C Distances in the MLS Point Cloud}
%   \label{fig:grossError}
% \end{minipage}


% \end{document}
